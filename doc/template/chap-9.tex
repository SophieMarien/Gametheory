\chapter{FlipIt game with virus propagation}
\label{cha:9}
%\documentclass[10pt]{article}
%\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%			Introduction Chapter 1				%%%%%%
%%%%%												%%%%%%
%%%%%												%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

\section{FlipIt game with virus propagation}
%------------------------------------------------%
%            Intro Game Theory 					 %
%------------------------------------------------%
\subsection{Actions of the attacker}
A virus has different kind of ways of making his way through a company network. We will describe the different ways of how the virus can propagate. For start we will say that the virus or worm will be dropped on Node i and that it has k numbers of neighbours. 
\begin{enumerate}
\item Node i is infected and will spread the virus or worm to every k neighbours and will stop infecting the neighbours in the next step
\item Node i is infected and will spread the virus or worm to every k neighbours and will keep on spreading the virus to the same neighbours in every next step
\item Node i is infected and will spread the virus to only one of the k neighbours and will stop infecting another neighbour in the next step
\item Node i is infected and will spread the virus to only one of the k neighbours and in the next step it will infect another one of the k neighbours 
\end{enumerate}

In the game that will be modelled in the paper we will use the settings of the first spreading method. We will not use method 2 because this kind of propagation will float the network. Because we use the settings of a mail system and contact in a mailing list the method of 3 and 4 are not used. \\
In the first method the node that has been infected can be again infected. If one of the neighbours infects the node again the node will infect his neighbours again. By using this spreading method we have three distinct states in which a node can be situated. An \textit{infected state}, a \textit{clean state} and a \textit{spreading state}. An infected state means that the node is infected and will not spread the virus to its neighbours, a clean state means that the node is not infected on that moment and a spreading state means that the node is infected and that it will spread the virus or worm to its neighbours in the next step.
We can argument this kind of propagation through a mail worm. \todo{voorbeeld geven van zo een worm}
%Another propagation method is that the virus works as a token. It will propagate to only one neighbour and continue to spread. 

The Attacker itself has two different ways of attacking the company network. It will only infected one node of the network and will wait for the virus to spread itself through the network. We will model two ways of attacks of an Attacker:
\begin{enumerate}
\item The attacker drops the virus on a random node on the network
\item The attacker drops the virus on a targeted node on the network
\end{enumerate}
The attacker in this game will put a virus or worm on one of the nodes in the network. (This will happen at random.) The attacker does not know on which node the virus will be dropped. We will use this randomness because \todo{feit uit security rapport symantec} most viruses are spread via a usb stick or a shared resource. If we use this spreading method where we have a targeted attack the attacker will have more information about the network. \\

The attacker can choose at which rate it will drop a virus on one of the nodes on the network. The cost of dropping a virus will be the same. It will not increase. If it will increase this means that the attacker will eventually drop out of the game because it becomes to expensive.\\
The attacker is in control over the game if it manages to infect a subset of all the resources of the company network.


\subsection{Actions of the defender}
The attacker wants to protect all the nodes of his network. It can do so by getting back control over the resources. We will assume that the defender of the network has knowledge over his own network. Which is convenient in the real world because a company has to know how his infrastructure looks like.\\

The defender has two possible ways of defending its network:
\begin{enumerate}
\item The defender flips all the nodes of his network
\item The defender will flip a subset of the nodes of his network
\end{enumerate}

The cost of flipping all the nods of the network will be greater than the cost of flipping a subset of nodes. We make this assumption because otherwise it will be beneficial for the defender to always flip all the nodes in the network.\\

We will also make the assumption that as a defender flips a node the node can get infected again. A flip will not be  correlated to a patch but to a clean-up. \todo{waarom geen patch, wormen kunnen veranderen gaandeweg}
\todo{andere mogelijkheid:} Another setting of the game can be that the flip of the defender is equal to a patch and that the resource cannot be infected any more. But with this case we deviate from the flipIt game, because the attacker cannot flip the resource any more. Unless we work with different virusses every time the attacker flips. We start with the less complex game of flipping is equal to a clean-up.

\subsection{Strategies of both players}
We explained what the actions of each player are. 

\section{Formal definition Game}

In this section we provide a formal definition of the game and the notation that we will use throughout the paper. 
\section*{Playing periodically with virus propagation}

This chapter explains how to model a FlipIt game with a virus propagation that infects a network. The first section explains the difference between a normal FlipIt game and a FlipIt game with virus propagation. The next section derives a formula to calculate the benefit for a FlipIt game with a virus propagation. In the last section we calculate the Nash equilibrium for the benefit formula.

\section{Explaining difference between FlipIt with and without virus propagation}
zelfde als in vorige chapter:

In chapter 2 the FlipIt game was explained.  This chapter starts from the specific case of a non-adaptive continuous FlipIt game where both players play a periodic strategy with a random phase. This choice is motivated by the assumption that in the practical situation of most organisations, the defence strategy is to periodically defend the network. This corresponds to a periodic defender strategy. \todo{bedrijven hebben niet het geld en de mankracht om zich daar mee bezig te houden en dan is periodisch verdedigen het handigste, bedrijven willen alles zo efficient en met de minste kost doen} To simplify the analysis in a first time, a periodic attacker strategy is assumed as well. Further research can investigate the effect of relaxing this assumption.\\


A FlipIt game consists of a single resource. To represent the security problem, the game now defines its single resource as a computer network with multiple
nodes. One of the players, the defender, will try to defend his network. The defender
will do this by flipping all the nodes of the network (i.e. the entire resource) in every move he plays. The
attacker, the other player, will try to infect all the nodes in the network. The attacker
will do this by flipping the node in the graph that can infect all the nodes in the
shortest time possible. After dropping a virus on the first node, it takes a while for the virus to infect the entire network. However, since the original FlipIt game works with a single resource that is always flipped entirely, the assumption is made that the attacker is considered to have gained the control over the resource only when all the nodes of the network have been infected, i.e. the entire resource has been flipped.

After dropping a virus on the first resource, it takes a while for the virus to infect
the entire network. The time that it takes for the virus to infect every node will be
denoted as parameter d. If we want to measure how long it takes for the virus to
infect all the nodes in the network, we have to calculate the shortest path from the
first infected node to the farthest node. This can be measured by a method that we
will explain in section []. Assume that an attacker attacks at time t, then only at time t + d he gains control over the entire network. If the defender flips the network before the period d has elapsed (so, somewhere between t and t+ d), then the attacker will never gain control over the entire network. Using this parameter d, a FlipIt game with virus propagation
can be modelled. 


\section{Benefit for FlipIt game with virus propagation}

Periodic Game with delay for the attacker:

\textbf{Case 1:} $\delta_{D} \leq \delta_{A} $(The defender plays at least as fast as the attacker.) \\

Let $r = \dfrac{\delta_{D}}{ \delta_{A} }$. The intervals between two consecutive defender's moves have length $\delta_{D}$. Consider a given defender move interval. The probability over the attacker's phase selection that the attacker moves in this interval is r. Given that the attacker moves within the interval, he moves exactly once within the interval (since $\delta_{D} \leq \delta_{A} $) and his move is distributed uniformly at random. \\

The expected period of attacker control within the interval would be r/2, without considering the delay. \\

However, because of the delay, the maximal time of control is reduced to $\delta_{D}-d$. There is a probability of \textit{r} that the attacker will move in the interval of the defender. The attacker has to play soon enough to gain control, meaning that the attacker has to play during the period of $\delta_{D}-d$ during the interval of the defender. There is $\dfrac{\delta_{D}-d}{\delta_{D}}$ probability that the attacker will move soon enough which gives the attacker a gain of $\dfrac{\delta_{D}-d}{2}$. If the attacker moves after the period of $\delta_{D}-d$, the gain of the attacker will be zero. The average gain rate of the attacker can be expressed as follows if we look at one interval of the defender:
\begin{equation}\label{first}
\beta_{A}(\alpha_{D},\alpha_{A}) = \dfrac {1}{\delta_{D}} [ \dfrac{\delta_{D}}{\delta_{A}} \cdot \dfrac{\delta_{D}-d}{\delta_{D}} \cdot \dfrac{\delta_{D}-d}{2} + \dfrac{\delta_{D}}{\delta_{A}} \cdot \dfrac{d}{\delta_{D}} \cdot 0 ]
\end{equation}

To complete the formula to derive the benefit function, the cost of moving is added. In the second formula we can see the formula of the original FlipIt game.
\begin{equation}\label{first}
\beta_{A}(\alpha_{D},\alpha_{A}) = \dfrac { (\delta_{D}-d) ^{2}} {2 \cdot \delta_{D}  \delta_{A}} - k_{A} \alpha_{A}
\end{equation}
\begin{equation}\label{first}
\beta_{A}(\alpha_{D},\alpha_{A}) = \dfrac { \delta_{D}} {2 \cdot \delta_{A}} - k_{A} \alpha_{A} + \dfrac{d}{\delta_{A}} + \dfrac{d^{2}}{2 \cdot \delta_{A} \delta_{D}}
\end{equation}
 
 The benefit of the defender is expressed as follows:
 \begin{equation}\label{first}
\beta_{D}(\alpha_{D},\alpha_{A}) = 1 - \dfrac { (\delta_{D}-d) ^{2}} {2 \cdot \delta_{D}  \delta_{A}} - k_{D} \alpha_{D}
\end{equation}



\textbf{Case 2:} $\delta_{A} \leq \delta_{D} $ (The attacker plays at least as fast as the defender.) \\

Let $r = \dfrac{\delta_{D}}{ \delta_{A} }$. The intervals between two consecutive attacker's moves have length $\delta_{A}$. Consider a given attackers move interval. The probability over the attacker's phase selection that the defender moves in this interval is $\dfrac{\delta_{D}}{ \delta_{A} } = (1/r)$. Given that the defender moves within the interval, he moves exactly once within the interval (since$\delta_{A} \leq \delta_{D} $) and his move is distributed uniformly at random. \\


\section{something}
\label{Cha:9:inrto}



Periodic Game with delay for the attacker:

\textbf{Case 1:} $\delta_{D} \leq \delta_{A} $(The defender plays at least as fast as the attacker.) \\


Let $r = \dfrac{\delta_{D}}{ \delta_{A} }$. The intervals between two consecutive defender's moves have length $\delta_{D}$. Consider a given defender move interval. The probability over the attacker's phase selection that the attacker moves in this interval is r. Given that the attacker moves within the interval, he moves exactly once within the interval (since $\delta_{D} \leq \delta_{A} $) and his move is distributed uniformly at random. \\

The expected period of attacker control within the interval would be r/2, without considering the delay. \\

However, because of the delay, the maximal time of control is reduced to $\delta_{D}-d$. If we consider a duration of $\delta_{D} \cdot \delta_{A}$ the attacker will play $\delta_{D}$ times. If the attacker plays soon enough it will get a gain of $\dfrac{\delta_{D}-d}{2}$ in $\delta_{D}-d$ of the cases. In \textit{d} cases it will receive a gain of zero. This is the case were the duration of the delay causes the defender to play before the attacker can get control over the resource. 
So the gain of the attacker can be expressed as follows:
\begin{equation}\label{first}
Gain =  \dfrac{\delta_{D}-d}{2} \cdot (\delta_{D}-d) + 0 \cdot d = \dfrac{\delta_{D}-d}{2} \cdot (\delta_{D}-d)
\end{equation}

The benefit of the attacker can be expressed as follows

\begin{equation}\label{first}
\beta_{A}(\alpha_{D},\alpha_{A}) = \dfrac { (\delta_{D}-d) ^{2}} {2 \cdot \delta_{D}  \delta_{A}} + k_{A} \cdot \alpha_{A}
\end{equation}
\begin{equation}\label{first}
\beta_{A}(\alpha_{D},\alpha_{A}) = \dfrac { \delta_{D}} {2 \cdot \delta_{A}} + k_{A} \cdot \alpha_{A} + \dfrac{d}{\delta_{A}} + \dfrac{d^{2}}{2 \cdot \delta_{A} \delta_{D}}
\end{equation}
\\

The benefit of the defender is then:

\begin{equation}\label{first}
\beta_{D}(\alpha_{D},\alpha_{A}) = 1 - \dfrac { (\delta_{D}-d) ^{2}} {2 \cdot \delta_{D} \cdot \delta_{A}} + k_{D} \cdot \alpha_{D}
\end{equation}
\begin{equation}\label{first}
\beta_{D}(\alpha_{D},\alpha_{A}) = 1 - \dfrac { \delta_{D}} {2 \cdot \delta_{A}} + k_{D} \cdot \alpha_{D} - \dfrac{d}{\delta_{A}}- \dfrac{d^{2}}{2 \cdot \delta_{A} \delta_{D}}
\end{equation}


\textbf{Case 2:} $\delta_{A} \leq \delta_{D} $ (The attacker plays at least as fast as the defender.) \\

Let $r = \dfrac{\delta_{D}}{ \delta_{A} }$. The intervals between two consecutive attacker's moves have length $\delta_{A}$. Consider a given attackers move interval. The probability over the attacker's phase selection that the defender moves in this interval is $\dfrac{\delta_{D}}{ \delta_{A} } = (1/r)$. Given that the defender moves within the interval, he moves exactly once within the interval (since$\delta_{A} \leq \delta_{D} $) and his move is distributed uniformly at random. \\

If we consider a duration of $\delta_{A} \cdot \delta_{D} $ there is a probability of $\dfrac{\delta_{A} } {\delta_{D}} $ that the defender moves within the interval of the attacker. The defender will then receive an average gain of $\dfrac{\delta_{A}} {2} $. There is $1- \dfrac{\delta_{A} } {\delta_{D}} $ probability that the defender will not move in the interval of the attacker and so the defender will receive no gain. The benefit can be expressed as follows when the  defender plays $\delta_{D}$ times during a duration of $\delta_{A} \cdot \delta_{D}$:
\begin{equation}\label{first}
\beta_{D}(\alpha_{D},\alpha_{A}) = \dfrac { 1} {\delta_{A} \delta_{D}} \cdot \delta_{D} \cdot [ \dfrac{\delta_{A}}{\delta_{D}} \cdot \dfrac{\delta_{A}}{2}+[ 1-\dfrac{\delta_{A}}{ \delta_{D}}] \cdot 0 ] + k_{D} \cdot \alpha_{D}
\end{equation}
\begin{equation}\label{first}
\beta_{D}(\alpha_{D},\alpha_{A}) = \dfrac {\delta_{A} }{2 \cdot \delta_{D}} + k_{D} \cdot \alpha_{D} $$same as the FlipIt solution$$
\end{equation}

However, because of the delay, the maximal time of control of the defender is increased by d. In other words, the defender has some benefit time of d before the attacker really gains control over the resource, meaning that the attacker gains control only after $\delta_{A}+d$ instead of after $\delta_{A}$. So, when the defender plays, with a probability of $\dfrac{\delta_{A} } {\delta_{D}} $, the expected gain of the defender's control in this interval would be more than half of the period $\delta_{A} $: it is $\dfrac{\delta_{A} + d}{2}$. There is $1- \dfrac{\delta_{A} } {\delta_{D}} $ probability that the defender will not move in the interval of the attacker but because of the delay the defender will receive a gain of d. So the benefit of the defender can be expressed as:
\begin{equation}\label{first}
\beta_{D}(\alpha_{D},\alpha_{A}) = \dfrac { 1} {\delta_{A} \delta_{D}} \cdot \delta_{D} \cdot [ \dfrac{\delta_{A} }{\delta_{D}} \cdot \dfrac{\delta_{A} + d}{2}+[ 1-\dfrac{\delta_{A}}{ \delta_{D}}] \cdot d ] + k_{D} \cdot \alpha_{D}
\end{equation}
\begin{equation}\label{first}
\beta_{D}(\alpha_{D},\alpha_{A}) = \dfrac {\delta_{A} - d}{2 \cdot \delta_{D}} + \dfrac{d}{\delta_{A}}  + k_{D} \cdot \alpha_{D}
\end{equation}

The benefit of the attacker is expressed as follows:
\begin{equation}\label{first}
\beta_{A}(\alpha_{D},\alpha_{A}) = 1- [ \dfrac {\delta_{A} - d}{2 \cdot \delta_{D}} + \dfrac{d}{\delta_{A}}  ] + k_{A} \cdot \alpha_{A}
\end{equation}

\section{Simulation}
%nce the defender has played, it takes 1 time until the attacker plays and the defender loses control again. Therefere, the expected period of attacker control within the interval would be 1/2.1/0, without considering the delay.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 

%\end{document}
