@misc{Barea2003,
abstract = {In this paper we present a new method to guide mobile robots. An eye-control device based on electro-oculography (EOG) is designed to develop a system for assisted mobility. Control is made by means eye movements detected using electro-oculographic potential. Using an inverse eye model, the saccadic eye movements can be detected and know where the user is looking. This control technique can be useful in multiple applications, but in this work it is used to guide a wheelchair for helping people with severe disabilities. The system consists of a standard electric wheelchair, an on-board computer, sensors and a graphical user interface. Finally, we comment on some experimental results and conclusions about electro-oculographic guidance using ocular commands.},
author = {Barea, R. and Boquete, L. and Bergasa, L. M. and Lopez, E. and Mazo, M.},
booktitle = {The International Journal of Robotics Research},
doi = {10.1177/02783649030227012},
issn = {0278-3649},
pages = {641--652},
title = {{Electro-Oculographic Guidance of a Wheelchair Using Eye Movements Codification}},
volume = {22},
year = {2003}
}
@article{Bourhis1998,
abstract = {In the smart wheelchair field the research problematics consists in applying methods coming from mobile robotics to navigation assistance for people with motor disabilities. In this paper we detail the constraints and the specificities of this application. From this study we deduce the need to obtain a cooperation between the human operator and the machine in order to achieve a mobility task. To illustrate this purpose, we describe a mobile robot architecture which facilitates task and information sharing and trading between man and machine.},
author = {Bourhis, G and Agostini, Y},
doi = {10.1023/A:1007934111358},
issn = {0921-0296},
journal = {Journal of Intelligent and Robotic systems},
keywords = {man-machine cooperation,mobile robotics,powered wheelchair},
pages = {39--50},
title = {{The VAHM robotized wheelchair: System architecture and human-machine interaction}},
volume = {22},
year = {1998}
}
@inproceedings{Carlson2008,
abstract = {Powered wheelchair users want to be active drivers, not just passengers. However, in some situations (varying from person to person), they may require assistance; hence, research is being carried out into the development of 'smart' wheelchairs. Predominantly, this research has been derived from the field of mobile robotics, focussing on creating autonomous systems, which unfortunately tend to treat the human as little more than a precious piece of cargo. Instead, the design should be based around each individual user's abilities and desires, maximising the amount of control they are given. In this paper, we look at how collaborative control techniques can be used to achieve this, offering the user help, as and when it is required. We then evaluate the effects of this collaboration, which is built by predicting user intentions and responding to these predictions with adaptable levels of assistance.},
author = {Carlson, Tom and Demiris, Yiannis},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2008.4543814},
isbn = {9781424416479},
issn = {10504729},
pages = {3926--3931},
title = {{Human-wheelchair collaboration through prediction of intention and adaptive assistance}},
year = {2008}
}
@article{Christensen2005,
author = {Christensen, HV and Garcia, JC},
file = {:C$\backslash$:/Users/Jeroen/Dropbox/Thesis/papers and documentation/infrared\_headmovement\_article.pdf:pdf},
journal = {\ldots the Advancement of Assistive Technology in \ldots},
keywords = {head joystick,head sensor,hmi,infrared},
pages = {1--5},
title = {{Infrared non-contact head sensor for control of wheelchair movements}},
year = {2005}
}
@article{Craig2005,
abstract = {Loss of mobility can occur for a variety of reasons,such as spinal cord injury or motor neurone disease. The onset of these conditions often brings with it an associated loss of personal independence, which is primarily due to the fact that the sufferer is no longer able to control their mobility. This project aims to address this problem through the creation of a head movement based wheelchair control system. Using a personal digital assistant (PDA) artificial intelligence techniques on an embedded LINUX operating system, a wireless head movement wheelchair control system has been designed and implemented. This system provides relief for sufferers of conditions which inhibit mobility through a method of wheelchair control which offers enhanced ease of use, attractiveness and independence.},
author = {Craig, D A and Nguyen, H T},
doi = {10.1109/IEMBS.2005.1616529},
isbn = {0-7803-8741-4},
issn = {1557-170X},
journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
pages = {772--775},
pmid = {17282298},
title = {{Wireless Real-Time Head Movement System Using a Personal Digital Assistant (PDA) for Control of a Power Wheelchair.}},
volume = {1},
year = {2005}
}
@phdthesis{Daemen2007,
author = {Daemen, Yves and Billiet, Tom},
file = {:C$\backslash$:/Users/Jeroen/Dropbox/Thesis/papers and documentation/eindwerk.pdf:pdf},
title = {{Visuele interface voor mindervaliden Besturing van een rolstoel via hoofd- en oogbewegingen}},
year = {2007}
}
@article{Demeester2012,
author = {Demeester, Eric and H\"{u}ntemann, Alexander},
file = {:C$\backslash$:/Users/Jeroen/Dropbox/Thesis/papers and documentation/demeester\_ISR2012\_ML\_MAP\_POMDP\_final\_s.pdf:pdf},
journal = {status: \ldots},
keywords = {-robotic wheelchair,estimation,intention,plan recognition,shared control,switch interface},
title = {{ML, MAP and greedy POMDP shared control: comparison of wheelchair navigation assistance for switch interfaces}},
year = {2012}
}
@article{Demeester2012a,
author = {Demeester, Eric and Poorten, Emmanuel Vander and Philips, Johan and H\"{u}ntemann, Alexander},
file = {:C$\backslash$:/Users/Jeroen/Dropbox/Thesis/papers and documentation/demeester\_ISR2012\_collisionchecking\_local\_paths\_final\_s.pdf:pdf},
keywords = {-path planning,1,a goal pose in,cf,checking,collision,collision avoidance,fig,from the robot,motion planning,neighborhood,s,s current pose to,the robot,this intention is estimated},
number = {1},
title = {{Design and evaluation of a lookup-table based collision-checking approach for fixed sets of mobile robot paths}},
year = {2012}
}
@inproceedings{Felzer2007,
abstract = {This paper deals with various ways of controlling an electrically powered wheelchair beyond the usual method involving a manual joystick. The main focus is on the newest$\backslash$nversion of HaWCoS -- the ''HAnds-free Wheelchair COntrol System'' -- allowing persons with severe disabilities to reliably navigate a power wheelchair without the need to use the hands. All the user has to do is to produce a sequence of tiny contractions of an arbitrary muscle, e.g., by raising the eyebrow. The working prototype of the system, which has been realized as a stand-alone device, is introduced in detail, together with a closer look at the muscle-based control principle and a brief description of a PC-based simulator. Finally, the advantages and the drawbacks of the system are discussed on the basis of a rather simple real-life experiment. $\backslash$n},
author = {Felzer, T and Nordmann, R},
booktitle = {Proc of the 1st International IEEE-BAIS Symposium on Research on Assistive Technologies},
pages = {67--74},
title = {{Alternative wheelchair control}},
volume = {7},
year = {2007}
}
@article{Huntemann2011,
author = {H\"{u}ntemann, A},
file = {:C$\backslash$:/Users/Jeroen/Dropbox/Thesis/papers and documentation/thesis\_alexander\_huntemann\_Probabilistic\_human-robot\_navigation.pdf:pdf},
isbn = {9789460183256},
number = {March},
title = {{Probabilistic Human-Robot Navigationâ€“Plan recognition, user modelling and shared control for robotic wheelchairs}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Probabilistic+Human-Robot+Navigation+Plan+Recognition+,+User+Modelling+and+Shared+Control+for+Robotic+Wheelchairs\#1},
year = {2011}
}
@article{Huo2009,
abstract = {Tongue drive system (TDS) is a tongue-operated, minimally invasive, unobtrusive, noncontact, and wireless assistive technology that infers users' intentions by detecting and classifying their voluntary tongue motions, and translating them to user-defined commands. We have developed customized interface circuitry between an external TDS (eTDS) prototype and a commercial powered wheelchair (PWC) as well as three control strategies to evaluate the tongue motion as an alternative control input for wheeled mobility. We tested the eTDS performance in driving PWCs on 12 able-bodied human subjects, of which 11 were novice. The results showed that all subjects could complete navigation tasks by operating the PWC using their tongue motions. Despite little prior experience, the average time using the eTDS and the tongue was only approximately three times longer than using a joystick and the fingers. Navigation time was strongly dependant on the number of issued commands, which reduced by gaining experience. Particularly, the unintended issued commands (the Midas touch problem) were rare, demonstrating the effectiveness of the tongue tracking and external magnetic field cancellation algorithms as well as the safety of the TDS for wheeled mobility.},
author = {Huo, Xueliang and Ghovanloo, Maysam},
doi = {10.1109/TBME.2009.2018632},
issn = {00189294},
journal = {IEEE Transactions on Biomedical Engineering},
keywords = {Assistive technologies (ATs),Environmental control,Magnetic sensors,Telemetry,Tongue motion,Wheeled mobility},
pages = {1719--1726},
pmid = {19362901},
title = {{Using unconstrained tongue motion as an alternative control mechanism for wheeled mobility}},
volume = {56},
year = {2009}
}
@article{Huo2010,
abstract = {The tongue drive system (TDS) is an unobtrusive, minimally invasive, wearable and wireless tongue-computer interface (TCI), which can infer its users' intentions, represented in their volitional tongue movements, by detecting the position of a small permanent magnetic tracer attached to the users' tongues. Any specific tongue movements can be translated into user-defined commands and used to access and control various devices in the users' environments. The latest external TDS (eTDS) prototype is built on a wireless headphone and interfaced to a laptop PC and a powered wheelchair. Using customized sensor signal processing algorithms and graphical user interface, the eTDS performance was evaluated by 13 naive subjects with high-level spinal cord injuries (C2-C5) at the Shepherd Center in Atlanta, GA. Results of the human trial show that an average information transfer rate of 95 bits/min was achieved for computer access with 82\% accuracy. This information transfer rate is about two times higher than the EEG-based BCIs that are tested on human subjects. It was also demonstrated that the subjects had immediate and full control over the powered wheelchair to the extent that they were able to perform complex wheelchair navigation tasks, such as driving through an obstacle course.},
author = {Huo, Xueliang and Ghovanloo, Maysam},
doi = {10.1088/1741-2560/7/2/026008},
issn = {1741-2560},
journal = {Journal of neural engineering},
pages = {26008},
pmid = {20332552},
title = {{Evaluation of a wireless wearable tongue-computer interface by individuals with high-level spinal cord injuries.}},
volume = {7},
year = {2010}
}
@misc{Jacob1991,
abstract = {In seeking hitherto-unused methods by which users and computers can comrnumcate, we investigate the usefulness of eye movements as a fast and convenient auxiliary user-to-computer communication mode. The barrier to exploiting this medium has not been eye-tracking tech- nology but the study of interaction techniques that incorporate eye movements mto the user- computer dialogue in a natural and unobtrusive way This paper discusses some of the human factors and technical considerations that arise in trying to use eye movements as an input medium, describes our approach and the first eye movement-based interaction techniques that we have devised and implemented in our laboratory, and reports our experiences and observa tions on them.},
author = {Jacob, Robert J. K.},
booktitle = {ACM Transactions on Information Systems},
doi = {10.1145/123078.128728},
isbn = {1046-8188},
issn = {10468188},
pages = {152--169},
title = {{The use of eye movements in human-computer interaction techniques: what you look at is what you get}},
volume = {9},
year = {1991}
}
@inproceedings{Kobayashi2011,
abstract = {This video presents our ongoing work developing a robotic wheelchair that can move automatically alongside a caregiver. Recently, several robotic/intelligent wheelchairs possessing autonomous functions for reaching a goal and/or user-friendly interfaces have been proposed. Although ideally wheelchair users may wish to go out alone, they are often accompanied by caregivers. Therefore, it is important to consider how to reduce the caregivers' load and support their activities and facilitate communication between the wheelchair user and caregiver. Moreover, a sociologist pointed out that when a wheelchair user is accompanied by a companion, the latter is inevitably seen as a caregiver [1]. In other words, the equality of the relationship is publicly undermined when the wheelchair is pushed by a companion. Hence, we propose a robotic wheelchair which can move alongside a caregiver or companion, and facilitate easy communication between them and the wheelchair user. However, it is not always desirable for a caregiver to be alongside a wheelchair. For instance, a caregiver may step in front of the wheelchair to open a door, and pedestrians may be encumbered by the wheelchair and companion if they move along side-by-side in a narrow corridor. To cope with these problems, our robotic wheelchair can move alongside a caregiver collaboratively depending on the circumstances. A laser range sensor is employed to track the caregiver and observe the environment around the wheelchair [2]. When obstacles are detected in the wheelchair's path of motion, it adjusts its position accordingly. In the video we demonstrate these functions of our robotic wheelchair. We are now conducting experiments to confirm the effectiveness of our wheelchair at an elderly care center in Japan.},
author = {Kobayashi, Y and Kinpara, Y and Takano, E and Kuno, Y and Yamazaki, K and Yamazaki, A},
booktitle = {Human-Robot Interaction (HRI), 2011 6th ACM/IEEE International Conference on},
isbn = {2167-2121},
pages = {407},
title = {{A wheelchair which can automatically move alongside a caregiver}},
year = {2011}
}
@article{Levine1999,
abstract = {The NavChair Assistive Wheelchair Navigation System [7] is an adaptive shared control system being developed to provide mobility to those individuals who would otherwise find it difficult or impossible to use a power wheelchair due to cognitive, perceptual, or motor impairments. The NavChair provides task-specific navigation assistance to the wheelchair operator in the form of several distinct operating modes, each of which distributes control differently between the wheelchair and the operator. This paper describes the NavChair's mechanism for automatically selecting the most appropriate operating mode based on a combination of the wheelchair's immediate situation and its global location. Results from two experimental evaluations of the adaptation method are presented.},
author = {Levine, S. P. and Bell, D. A. and Jaros, L. A. and Simpson, R. C. and Koren, Y. and Borenstein, J.},
doi = {10.1109/86.808948},
isbn = {1063-6528 (Print)},
issn = {10636528},
journal = {IEEE Transactions on Rehabilitation Engineering},
keywords = {Obstacle avoidance,Power wheelchairs,Smart wheelchairs,Wheelchair control,Wheelchair navigation},
pages = {443--451},
pmid = {10609633},
title = {{The NavChair Assistive Wheelchair Navigation System}},
volume = {7},
year = {1999}
}
@book{Murray1994,
abstract = {A Mathematical Introduction to Robotic Manipulation presents a mathematical formulation of the kinematics, dynamics, and control of robot manipulators. It uses an elegant set of mathematical tools that emphasizes the geometry of robot motion and allows a large class of robotic manipulation problems to be analyzed within a unified framework.The foundation of the book is a derivation of robot kinematics using the product of the exponentials formula. The authors explore the kinematics of open-chain manipulators and multifingered robot hands, present an analysis of the dynamics and control of robot systems, discuss the specification and control of internal forces and internal motions, and address the implications of the nonholonomic nature of rolling contact are addressed, as well.The wealth of information, numerous examples, and exercises make A Mathematical Introduction to Robotic Manipulation valuable as both a reference for robotics researchers and a text for students in advanced robotics courses.},
author = {Murray, Richard M and Li, Zexiang and Sastry, S Shankar},
booktitle = {Book},
doi = {10.1.1.169.3957},
institution = {University of California},
isbn = {9780849379819},
issn = {0849379814},
number = {2},
pages = {480},
pmid = {2997678},
publisher = {CRC Press},
title = {{A Mathematical Introduction to Robotic Manipulation}},
volume = {29},
year = {1994}
}
@inproceedings{Nguyen2012,
abstract = {This paper is concerned with the operational performance of a semi-autonomous wheelchair system named TIM (Thought-controlled Intelligent Machine), which uses cameras in a system configuration modeled on the vision system of a horse. This new camera configuration utilizes stereoscopic vision for 3-Dimensional (3D) depth perception and mapping ahead of the wheelchair, combined with a spherical camera system for 360-degrees of monocular vision. The unique combination allows for static components of an unknown environment to be mapped and any surrounding dynamic obstacles to be detected, during real-time autonomous navigation, minimizing blind-spots and preventing accidental collisions with people or obstacles. Combining this vision system with a shared control strategy provides intelligent assistive guidance during wheelchair navigation, and can accompany any hands-free wheelchair control technology for people with severe physical disability. Testing of this system in crowded dynamic environments has displayed the feasibility and real-time performance of this system when assisting hands-free control technologies, in this case being a proof-of-concept brain-computer interface (BCI).},
author = {Nguyen, Jordan S. and Nguyen, Tuan Nghia and Tran, Yvonne and Su, Steven W. and Craig, Ashley and Nguyen, Hung T.},
booktitle = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
doi = {10.1109/EMBC.2012.6346612},
isbn = {9781424441198},
issn = {1557170X},
pages = {3069--3072},
pmid = {23366573},
title = {{Real-time performance of a hands-free semi-autonomous wheelchair system using a combination of stereoscopic and spherical vision}},
year = {2012}
}
@misc{Oracle,
author = {Oracle},
keywords = {javax.swing package},
title = {{Javax swing}},
url = {http://docs.oracle.com/javase/7/docs/api/javax/swing/package-summary.html},
urldate = {16/08/14}
}
@article{Postel1981,
author = {Postel, J.},
title = {{Transmission Control Protocol}},
url = {http://tools.ietf.org/html/rfc793},
year = {1981}
}
@article{Rebsamen2010,
abstract = {While brain-computer interfaces (BCIs) can provide communication to people who are locked-in, they suffer from a very low information transfer rate. Further, using a BCI requires a concentration effort and using it continuously can be tiring. The brain controlled wheelchair (BCW) described in this paper aims at providing mobility to BCI users despite these limitations, in a safe and efficient way. Using a slow but reliable P300 based BCI, the user selects a destination amongst a list of predefined locations. While the wheelchair moves on virtual guiding paths ensuring smooth, safe, and predictable trajectories, the user can stop the wheelchair by using a faster BCI. Experiments with nondisabled subjects demonstrated the efficiency of this strategy. Brain control was not affected when the wheelchair was in motion, and the BCW enabled the users to move to various locations in less time and with significantly less control effort than other control strategies proposed in the literature.},
author = {Rebsamen, Brice and Guan, Cuntai and Zhang, Haihong and Wang, Chuanchu and Teo, Cheeleong and Ang, Marcelo H. and Burdet, Etienne},
doi = {10.1109/TNSRE.2010.2049862},
isbn = {1534-4320},
issn = {15344320},
journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
keywords = {Braincomputer interface (BCI),P300,wheelchair},
pages = {590--598},
pmid = {20460212},
title = {{A brain controlled wheelchair to navigate in familiar environments}},
volume = {18},
year = {2010}
}
@misc{Rebsamen2007,
abstract = {Amyotrophic lateral sclerosis, or ALS, is a degenerative disease of the motor neurons that eventually leads to complete paralysis. We are developing a wheelchair system that can help ALS patients, and others who can't use physical interfaces such as joysticks or gaze tracking, regain some autonomy. The system must be usable in hospitals and homes with minimal infrastructure modification. It must be safe and relatively low cost and must provide optimal interaction between the user and the wheelchair within the constraints of the brain-computer interface. To this end, we have built the first working prototype of a brain-controlled wheelchair that can navigate inside a typical office or hospital environment. This article describes the BCW, our control strategy, and the system's performance in a typical building environment. This brain-controlled wheelchair prototype uses a P300 EEG signal and a motion guidance strategy to navigate in a building safely and efficiently without complex sensors or sensor processing},
author = {Rebsamen, Brice and Teo, Chee Leong and Zeng, Qiang and Ang, Marcelo H. and Burdet, Etienne and Guan, Cuntai and Zhang, Haihong and Laugier, Christian},
booktitle = {IEEE Intelligent Systems},
doi = {10.1109/MIS.2007.26},
isbn = {1541-1672},
issn = {15411672},
pages = {18--24},
title = {{Controlling a wheelchair indoors using thought}},
volume = {22},
year = {2007}
}
@article{Simpson1997,
abstract = {The NavChair Assistive Wheelchair Navigation System is being
developed to reduce the cognitive and physical requirements of operating
a power wheelchair. The NavChair is an adaptive shared control system,
shared in that control is divided between the wheelchair and the
wheelchair operator and adaptive in that how control is divided between
the wheelchair and the wheelchair operator varies based on current task
requirements. This paper describes the NavChair's method for
automatically allocating control between the wheelchair and its operator
and presents results evaluating the performance of the NavChair's
automatic adaptation mechanism from an experiment in which able-bodied
subjects used voice control to steer the NavChair through a navigation
task requiring several transitions between operating modes},
author = {Simpson, R.C. and Levine, S.P.},
doi = {10.1109/IROS.1997.655076},
isbn = {0-7803-4119-8},
journal = {Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97},
title = {{Adaptive shared control of a smart wheelchair operated by voice
control}},
volume = {2},
year = {1997}
}
@article{Simpson2002,
abstract = {Several researchers have described voice control mechanisms for a power wheelchair, but voice control has yet to become a commercially viable control alternative. One problem with voice control is that the voice's limited bandwidth renders it impossible to make frequent small adjustments to the wheelchair's velocity. One possible solution is to utilize voice control in combination with the navigation assistance provided by "smart wheelchairs," which use sensors to identify and avoid obstacles in the wheelchair's path. This paper describes an experiment that compares the performance of able-bodied subjects using voice control to operate a power wheelchair both with and without navigation assistance.},
author = {Simpson, Richard C. and Levine, Simon P.},
doi = {10.1109/TNSRE.2002.1031981},
issn = {15344320},
journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
pages = {122--125},
pmid = {12236450},
title = {{Voice control of a powered wheelchair}},
volume = {10},
year = {2002}
}
@inproceedings{Taha2008,
abstract = {This paper presents an intelligent decision-making agent to assist wheelchair users in their daily navigation activities. Several navigational techniques have been successfully developed in the past to assist with specific behaviours such as "door passing" or "corridor following". These shared control strategies normally require the user to manually select the level of assistance required during use. Recent research has seen a move towards more intelligent systems that focus on forecasting users' intentions based on current and past actions. However, these predictions have been typically limited to locations immediately surrounding the wheelchair. The key contribution of the work presented here is the ability to predict the users' intended destination at a larger scale, that of a typical office arena. The systems relies on minimal user input - obtained from a standard wheelchair joystick - in conjunction with a learned Partially Observable Markov Decision Process (POMDP), to estimate and subsequently drive the user to his destination. The projection is constantly being updated, allowing for true user- platform integration. This shifts users' focus from fine motor- skilled control to coarse control broadly intended to convey intention. Successful simulation and experimental results on a real wheelchair robot demonstrate the validity of the approach.},
author = {Taha, Tarek and Mir\'{o}, Jaime Valls and Dissanayake, Gamini},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2008.4543813},
isbn = {9781424416479},
issn = {10504729},
pages = {3920--3925},
title = {{POMDP-based long-term user intention prediction for wheelchair navigation}},
year = {2008}
}
@article{Taylor2003,
abstract = { Head movement has been used as a control interface for people with motor impairments in a range of applications. Chin operated joysticks and switch arrays have been incorporated in control systems for electric wheelchairs but have several disadvantages, including being difficult to operate and aesthetically unattractive. A prototype wheelchair control interface has been developed that makes use of an artificial neural network (ANN) to recognize commands given by head movement. This paper presents the results of an experimental investigation of the ANN's performance in terms of classification accuracy and delay. It goes on to compare the results of disabled with able-bodied users, and assesses the effect of providing real-time feedback to the user. The results obtained indicate that ANN techniques can be used to classify head movements sufficiently quickly and accurately to be used in a practical interface. The provision of graphical real-time feedback does not appear to be crucial, but may be of benefit for particular cases.},
author = {Taylor, P.B. and Nguyen, H.T.},
doi = {10.1109/IEMBS.2003.1279669},
isbn = {0-7803-7789-3},
issn = {1094-687X},
journal = {Proceedings of the 25th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (IEEE Cat. No.03CH37439)},
title = {{Performance of a head-movement interface for wheelchair control}},
volume = {2},
year = {2003}
}
@book{Thrun2002,
abstract = {Probabilistic robotics is a new and growing area in robotics, concerned with perception and control in the face of uncertainty. Building on the field of mathematical statistics, probabilistic robotics endows robots with a new level of robustness in real-world situations. This book introduces the reader to a wealth of techniques and algorithms in the field. All algorithms are based on a single overarching mathematical foundation. Each chapter provides example implementations in pseudo code, detailed mathematical derivations, discussions from a practitioner's perspective, and extensive lists of exercises and class projects. The book's Web site, http://www.probabilistic-robotics.org, has additional material. The book is relevant for anyone involved in robotic software development and scientific research. It will also be of interest to applied statisticians and engineers dealing with real-world sensor data.},
author = {Thrun, Sebastian and Burgard, W and Fox, D},
booktitle = {Communications of the ACM},
file = {:C$\backslash$:/Users/Jeroen/Dropbox/Thesis/papers and documentation/ProbabilisticRobotics.pdf:pdf},
number = {3},
pages = {1999--2000},
title = {{Probabilistic robotics}},
volume = {45},
year = {2005}
}
@article{Device,
author = {{Tobii Technology}},
file = {:C$\backslash$:/Users/Jeroen/Dropbox/Thesis/papers and documentation/MyTobii\_P10\_Leaflet\_us.pdf:pdf},
title = {{MyTobii P10 user manual}}
}
@article{Tobii2010,
abstract = {Eye tracking commonly refers to the technique used to record and measure eye movements. In the last two to three decades we have witnessed a rapid evolution in eye tracking technology with systems becoming easier to operate and less intrusive to the test subjects. As a consequence the user base has also expanded with eye tracking being used more commonly in different research and commercial projects. The aim of this paper is to give a brief introduction to the human visual system, and to explain how eye movements are recorded and processed by Tobii Eye Trackers. Some basic concepts and issues related to remote eye tracking and eye movement data interpretation are also briefly discussed. File},
author = {{Tobii Technology}},
title = {{Tobii Eye Tracking}},
url = {http://www.tobii.com/Global/Analysis/Training/WhitePapers/Tobii\_EyeTracking\_Introduction\_WhitePaper.pdf?epslanguage=en},
year = {2010}
}
@article{Yanco2000,
abstract = {An assistive robotic wheelchair system should allow its user to travel more efficiently and with greater ease. The robotic wheelchair system described in this thesis, Whee- lesley, performs semi-autonomous navigation for its user, taking high-level directional commands and performing the low-level navigation required to avoid obstacles and stay on a safe path. The system consists of a standard electric wheelchair with an on-board computer formotor control, a vision system running on an off-the-shelf note- book computer, sensors, and a graphical user interface running on a tray mounted notebook computer. Most other research on robotic wheelchairs only addresses indoor navigation. The Wheelesley system can travel both indoors and outdoors using specialized navigation modes; there is a control algorithm for indoor navigation and a control algorithm for outdoor navigation. User tests have been conducted for both control modes to com- pare robotic assisted control against manual control. Robotic assisted control requires 71\% less effort for indoor navigation and 88\% less effort for outdoor navigation. In addition, the total time needed to travel between two points is reduced since less time is spent waiting to scan to the desired commands. The system switches automatically between navigation modes through the use of a novel indoor/outdoor detector. The detector is comprised of an ultrasonic transducer, three light-to-voltage optical sensors and a thermistor. Adecision tree learned by C4.5 using data collected in a variety of indoor and outdoor conditions classified a test set correctly 98.3\% of the time. The system can be easily customized for the access method(s) required by each user. This thesis describes customization of the user interface for two different access methods: eye tracking, an uncommon access method for a wheelchair, and single switch scanning, which is considered the driving method of last resort on standard powered wheelchairs. The wheelchair system and its interface was evaluated by a group of physical therapists.},
author = {Yanco, HA},
file = {:C$\backslash$:/Users/Jeroen/Dropbox/Thesis/papers and documentation/eagle\_eye\_holly\_yanco.pdf:pdf},
journal = {Science},
number = {1991},
title = {{Shared user-computer control of a robotic wheelchair system}},
year = {2000}
}
@misc{lighttouch,
keywords = {lighttouch},
mendeley-tags = {lighttouch},
title = {{Light Touch Joystick | www.click2go.ie}},
url = {http://www.click2go.ie/blog/light-touch-joystick/},
urldate = {14/08/14}
}
@misc{sip,
title = {{Sip/Puff Switch}},
url = {http://www.orin.com/access/sip\_puff/},
urldate = {15/08/14}
}
@misc{Humanbenchmark,
keywords = {benchmark,data,flash,game,graphs,human,human benchmark,reaction,reaction time,reflex,statistics,stats,test,time},
mendeley-tags = {benchmark},
title = {{Human Benchmark - Reaction Time Stats}},
url = {http://www.humanbenchmark.com/tests/reactiontime/stats.php},
urldate = {16/08/14}
}
@misc{Tobii2014,
abstract = {The Tobii X2-60 Eye Tracker is a revolutionary small and versatile 60 Hz eye tracking research system, powered by the latest generation innovative eye tracking technology from Tobii. The modular eye tracker with a single USB cable provide a truly portable solution, ideal for studying human behavior in surroundings that are familiar to the participants, such as in their homes, clinics, schools or malls. Participants can behave naturally thanks to uniquely large freedom of head movement. Researchers can rely on unparalleled tracking accuracy within the whole track box and being able to track basically any participant. Offering maximum flexibility, portability, highly accurate data, and very robust tracking at a lower price compared with previous Tobii eye trackers, the Tobii X2-60 Eye Tracker makes it possible to integrate eye tracking into numerous varieties of human behavior studies in psychology, usability and market research.},
title = {{Tobii X2-60 Eye Tracker}},
url = {http://www.tobii.com/zh-CN/eye-tracking-research/global/products/hardware/tobii-x2-60-eye-tracker/},
year = {2014}
}
